#　モンテカルロ木探索アルゴリズム (MCTS)
P.108

ゲームに関する戦略的知識なしにゲーム状態を評価する方法を提供する。
ランダムにゲームをシュミレートして局面がどれほど良いか推定する。

ロールアウト(プレイアウト) = ランダムなゲームプレイを一回行うこと

## MCTSアルゴリズムのステップ
1. 新しい局面をMCTSの木に追加する。
2. その局面からランダムなゲームをシュミレートする
3. そのランダムなゲームの結果で木の統計情報を更新する

この一連の処理を使用可能な時間の間できるだけ多く繰り返す。
木の最上部にある統計は、どの手を選択するかを示す。

リーフ = 木の最下部

# UCT (upper confidence bound for trees)
各手番に費やす時間が限られている。これは一定数のロールアウトしか実行できないことを意味する。
限られた回数をどのように配分するかを決める戦略が必要。
標準的な戦略は、UCT式と呼ばれている。
UCT式 = ２つの相反する目標の間のバランスをとる。

## 最初の目標
最初の目標は最前の手を調べるために時間を費やすこと。
この目標は利用(exploitation)と呼ばれている。

これは、推定されえた勝率が最も高い手にもっと多くのロールアウトを割り当てることを意味している。

## 二番目の目標
ノードを数回訪問しただけでは、推定値は大きく外れている可能性がある。
一番訪問していない枝についてより正確な推定値を得ること。
この目標は探索(exploration)と呼ばれている。

利用と探索のトレードオフは、試行錯誤によるアルゴリズムに共通する特性。


## 計算
考慮中の各ノードについいて、利用の目標を表す勝率Wを計算します。
探索を表すために、c√logN/nを計算
する。

N = ロールアウトの総数
n = 考慮中のノードで開始されたロールアウトの数。
c = 利用と探索の間の優先度のバランスを表すパラメータ。

![alt](https://latex.codecogs.com/gif.latex?w&space;&plus;&space;c\sqrt{\frac{\log_{e}N}{n}})

cの値が大きければ、最も探索されていないノードにもっと多くの時間を費やす。
cの値が小さければ、もっとも有望なノードの評価を得るために多くの時間を費やす。
最も効果的なゲームプレイヤーを作るcの選択は通常、試行錯誤により行われる。
1.5あたりから始めて、そこから実験するのが良い。




